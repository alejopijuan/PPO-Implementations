{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, device(type='cpu'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions import Categorical\n",
    "from multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "#CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "use_cuda,device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number on envs we'll be running in parallel\n",
    "num_envs = 8\n",
    "env_name = \"MountainCarContinuous-v0\"\n",
    "\n",
    "def make_env():\n",
    "    def _thunk():\n",
    "        env = gym.make(env_name)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "envs = [make_env() for i in range(num_envs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(m.bias, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Net\n",
    "#ActorCritic, for continuous action tasks\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size, std=0.0):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_outputs),\n",
    "        )\n",
    "        #self.log_std only for continuous action spaces.\n",
    "        self.log_std = nn.Parameter(torch.ones(1, num_outputs) * std)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        value = self.critic(x)\n",
    "        mu    = self.actor(x)\n",
    "        std   = self.log_std.exp().expand_as(mu)\n",
    "        #only difference is we're using Normal dist to sample actions from\n",
    "        #Gaussian distribution. Categorical() for discrete action space.\n",
    "        dist  = Normal(mu, std)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAE\n",
    "#gamma is discount factor for returns, tau is smoothing factor of GAE algo.\n",
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        #delta is Bellman equation minus value of the state\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        #moving average of advantages discounted by gamma * tau\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage):\n",
    "    batch_size = states.size(0)\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :]\n",
    "        \n",
    "        \n",
    "\n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param=0.2):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for state, action, old_log_probs, return_, advantage in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "            dist, value = model(state)   #pass state into network to get latest distribution and state value\n",
    "            entropy = dist.entropy().mean() #for inciting exploration\n",
    "            new_log_probs = dist.log_prob(action) #new log_probs of originally selected actions\n",
    "            \n",
    "            \n",
    "            ratio = (new_log_probs - old_log_probs).exp()\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage\n",
    "            \n",
    "            #CLIP LOSS\n",
    "            actor_loss  = - torch.min(surr1, surr2).mean()\n",
    "            #MSE LOSS between GAE returns and estimated value of the state\n",
    "            critic_loss = (return_ - value).pow(2).mean()\n",
    "            #discounted critic loss plus CLIP LOSS minus scaled entroy\n",
    "            loss = 0.5 * critic_loss + actor_loss - 0.001 * entropy\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs  = envs.observation_space.shape[0]\n",
    "num_outputs = envs.action_space.shape[0]\n",
    "\n",
    "#Hyper params:\n",
    "hidden_size      = 256   #neurons in hidden layer\n",
    "lr               = 3e-4  #passed to Adam optimizer    \n",
    "num_steps        = 1024   #num of transitions we sample for each training iter\n",
    "mini_batch_size  = 16     #num of samples randomly selected from stored data\n",
    "ppo_epochs       = 8     #num passes over entire training data\n",
    "threshold_reward = 90  #we'll stop training when we reach this reward in evaluation\n",
    "\n",
    "model = ActorCritic(num_inputs, num_outputs, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_frames = 50000\n",
    "frame_idx  = 0\n",
    "test_rewards = []\n",
    "\n",
    "state = envs.reset()\n",
    "early_stop = False\n",
    "\n",
    "while frame_idx < max_frames and not early_stop:\n",
    "\n",
    "    log_probs = []\n",
    "    values    = []\n",
    "    states    = []\n",
    "    actions   = []\n",
    "    rewards   = []\n",
    "    masks     = []\n",
    "    entropy = 0\n",
    "    \n",
    "    #each step generate state, action, reward, next_state from each env.\n",
    "    for _ in range(num_steps):\n",
    "        state = torch.FloatTensor(state).to(device) \n",
    "        dist, value = model(state) #state through netwwork to get prob dist and estimated V(s)\n",
    "\n",
    "        action = dist.sample()\n",
    "        #state, reward, done is list of results, 1 per env\n",
    "        #env.render()\n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy())\n",
    "\n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy += dist.entropy().mean()\n",
    "        \n",
    "        #Store log_probs, values, rewards, done_masks, states, actions. Each list num_steps long, each step num_envs wide.\n",
    "        log_probs.append(log_prob) #\n",
    "        values.append(value)\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx % 1000 == 0:\n",
    "            test_reward = np.mean([test_env() for _ in range(10)])\n",
    "            test_rewards.append(test_reward)\n",
    "            plot(frame_idx, test_rewards)\n",
    "            if test_reward > threshold_reward: early_stop = True\n",
    "            \n",
    "    #to calc returns correctly, run final next_state through network to get value\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    #run GAE. Loop backwards from recent experience.\n",
    "    returns = compute_gae(next_value, rewards, masks, values)\n",
    "    \n",
    "    #concatanate each list inside a torch tensor.\n",
    "    #list that was num_steps long, num_envs wide becomes num_steps*num_envs long\n",
    "    returns   = torch.cat(returns).detach()\n",
    "    log_probs = torch.cat(log_probs).detach()\n",
    "    values    = torch.cat(values).detach()\n",
    "    states    = torch.cat(states)\n",
    "    actions   = torch.cat(actions)\n",
    "    advantage = returns - values\n",
    "    \n",
    "    ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 reward: 92.50595489693949\n",
      "episode: 1 reward: 90.2429031923931\n",
      "episode: 2 reward: 90.46213745210656\n",
      "episode: 3 reward: 92.98511851341641\n",
      "episode: 4 reward: 88.24416834781347\n",
      "episode: 5 reward: 92.88827495482111\n",
      "episode: 6 reward: 90.60765836455347\n",
      "episode: 7 reward: 92.40094184886196\n",
      "episode: 8 reward: 89.37611127103935\n",
      "episode: 9 reward: 91.118402050449\n",
      "episode: 10 reward: 89.98251751223295\n",
      "episode: 11 reward: 93.99193749327159\n",
      "episode: 12 reward: 92.23811835895602\n",
      "episode: 13 reward: 88.81998365793334\n",
      "episode: 14 reward: 89.05165064709018\n",
      "episode: 15 reward: 91.89187652015232\n",
      "episode: 16 reward: 91.68700199669784\n",
      "episode: 17 reward: 90.31249531113625\n",
      "episode: 18 reward: 92.62575449360881\n",
      "episode: 19 reward: 93.5227400879799\n",
      "episode: 20 reward: 88.48039546172757\n",
      "episode: 21 reward: 92.26560479736753\n",
      "episode: 22 reward: 90.7838209253255\n",
      "episode: 23 reward: 91.81141319365696\n",
      "episode: 24 reward: 89.4528686981365\n",
      "episode: 25 reward: 86.02661005927848\n",
      "episode: 26 reward: 93.17166794360627\n",
      "episode: 27 reward: 89.98061098459493\n",
      "episode: 28 reward: 90.3036044909799\n",
      "episode: 29 reward: 86.95419524503363\n",
      "episode: 30 reward: 90.76681524235075\n",
      "episode: 31 reward: 91.60433821502443\n",
      "episode: 32 reward: 93.78634269778382\n",
      "episode: 33 reward: 88.05269483101385\n",
      "episode: 34 reward: 91.85590687386713\n",
      "episode: 35 reward: 87.90211884685115\n",
      "episode: 36 reward: 87.37936208078142\n",
      "episode: 37 reward: 94.11474544868788\n",
      "episode: 38 reward: 90.45540399572413\n",
      "episode: 39 reward: 89.59921514870494\n",
      "episode: 40 reward: 88.9440673070136\n",
      "episode: 41 reward: 89.01157279041556\n",
      "episode: 42 reward: 89.94190063929369\n",
      "episode: 43 reward: 87.97639290232719\n",
      "\n",
      "(10263, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Save trajectories for GAIL\n",
    "from itertools import count\n",
    "\n",
    "max_expert_num = 10000\n",
    "num_steps = 0\n",
    "expert_traj = []\n",
    "\n",
    "for i_episode in count():\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        action = dist.sample().cpu().numpy()[0]\n",
    "        #Show\n",
    "        \n",
    "        #Take action\n",
    "        \n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        expert_traj.append(np.hstack([state, action]))\n",
    "        num_steps += 1\n",
    "    \n",
    "    print(\"episode:\", i_episode, \"reward:\", total_reward)\n",
    "    \n",
    "    if num_steps >= max_expert_num:\n",
    "        break\n",
    "for _ in range(10):\n",
    "    test_env(True)        \n",
    "    time.sleep(3)       \n",
    "expert_traj = np.stack(expert_traj)\n",
    "print()\n",
    "print(expert_traj.shape)\n",
    "print()\n",
    "np.save(\"expert_traj_mntcarcont8.npy\", expert_traj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
